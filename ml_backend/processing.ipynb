{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e272862-c489-48b4-8d31-c6ac63c77adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rashmi Bekal\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\n",
      "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bafc394c-d750-422b-ab54-49027620a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c59db96-fcdd-4c90-a069-a29c8e2c2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal = './dataset/Abnormal'\n",
    "normal = './dataset/Normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "352cc392-2656-422c-a30e-8502905972b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11359 images.\n",
      "X shape: (11359, 64, 64, 3), y shape: (11359, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define paths\n",
    "abnormal_path = './dataset/Abnormal'\n",
    "normal_path = './dataset/Normal'\n",
    "\n",
    "# Initialize lists\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Load Abnormal images (label = 1)\n",
    "for img_file in os.listdir(abnormal_path):\n",
    "    img_path = os.path.join(abnormal_path, img_file)\n",
    "    try:\n",
    "        img = load_img(img_path, target_size=(64, 64) , color_mode='rgb')  # adjust size as needed\n",
    "        img_array = img_to_array(img)\n",
    "        X.append(img_array)\n",
    "        y.append(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file {img_path}: {e}\")\n",
    "\n",
    "# Load Normal images (label = 0)\n",
    "for img_file in os.listdir(normal_path):\n",
    "    img_path = os.path.join(normal_path, img_file)\n",
    "    try:\n",
    "        img = load_img(img_path, target_size=(64, 64), color_mode='rgb')\n",
    "        img_array = img_to_array(img)\n",
    "        X.append(img_array)\n",
    "        y.append(0)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file {img_path}: {e}\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X, dtype='float32') / 255.0  # Normalize\n",
    "y = np.array(y)\n",
    "\n",
    "# One-hot encode labels\n",
    "y = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Sanity check\n",
    "print(f\"Loaded {len(X)} images.\")\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93777737-cd92-4d30-b82a-5ac750a81a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11359 images.\n",
      "X shape: (11359, 64, 64, 3), y shape: (11359, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define paths\n",
    "abnormal_path = './dataset/Abnormal'\n",
    "normal_path = './dataset/Normal'\n",
    "\n",
    "# Initialize lists\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Load Abnormal images (label = 1)\n",
    "for img_file in os.listdir(abnormal_path):\n",
    "    img_path = os.path.join(abnormal_path, img_file)\n",
    "    try:\n",
    "        img = load_img(img_path, target_size=(64, 64) , color_mode='rgb')  # adjust size as needed\n",
    "        img_array = img_to_array(img)\n",
    "        X.append(img_array)\n",
    "        y.append(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file {img_path}: {e}\")\n",
    "\n",
    "# Load Normal images (label = 0)\n",
    "for img_file in os.listdir(normal_path):\n",
    "    img_path = os.path.join(normal_path, img_file)\n",
    "    try:\n",
    "        img = load_img(img_path, target_size=(64, 64), color_mode='rgb')\n",
    "        img_array = img_to_array(img)\n",
    "        X.append(img_array)\n",
    "        y.append(0)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file {img_path}: {e}\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X, dtype='float32') / 255.0  # Normalize\n",
    "y = np.array(y)\n",
    "\n",
    "# One-hot encode labels\n",
    "y = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Sanity check\n",
    "print(f\"Loaded {len(X)} images.\")\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9048a176-37f1-45b3-8a47-0e583ea96623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11359 images.\n",
      "X shape: (11359, 64, 64, 3), y shape: (11359, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define paths\n",
    "abnormal_path = './dataset/Abnormal'\n",
    "normal_path = './dataset/Normal'\n",
    "\n",
    "# Initialize lists\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Load Abnormal images (label = 1)\n",
    "for img_file in os.listdir(abnormal_path):\n",
    "    img_path = os.path.join(abnormal_path, img_file)\n",
    "    try:\n",
    "        img = load_img(img_path, target_size=(64, 64) , color_mode='rgb')  # adjust size as needed\n",
    "        img_array = img_to_array(img)\n",
    "        X.append(img_array)\n",
    "        y.append(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file {img_path}: {e}\")\n",
    "\n",
    "# Load Normal images (label = 0)\n",
    "for img_file in os.listdir(normal_path):\n",
    "    img_path = os.path.join(normal_path, img_file)\n",
    "    try:\n",
    "        img = load_img(img_path, target_size=(64, 64), color_mode='rgb')\n",
    "        img_array = img_to_array(img)\n",
    "        X.append(img_array)\n",
    "        y.append(0)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping file {img_path}: {e}\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X, dtype='float32') / 255.0  # Normalize\n",
    "y = np.array(y)\n",
    "\n",
    "# One-hot encode labels\n",
    "y = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Sanity check\n",
    "print(f\"Loaded {len(X)} images.\")\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f9bf02d-1a85-4868-bacc-251e4cd4a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6047a4e4-9be4-49c7-a48b-059b73854c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "  Normal: 4056\n",
      "  Abnormal: 5031\n",
      "Testing Set:\n",
      "  Normal: 981\n",
      "  Abnormal: 1291\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert one-hot encoded labels back to class indices\n",
    "y_train_labels = np.argmax(y_train, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Count in training set\n",
    "train_normal = np.sum(y_train_labels == 0)\n",
    "train_abnormal = np.sum(y_train_labels == 1)\n",
    "\n",
    "# Count in testing set\n",
    "test_normal = np.sum(y_test_labels == 0)\n",
    "test_abnormal = np.sum(y_test_labels == 1)\n",
    "\n",
    "print(\"Training Set:\")\n",
    "print(f\"  Normal: {train_normal}\")\n",
    "print(f\"  Abnormal: {train_abnormal}\")\n",
    "\n",
    "print(\"Testing Set:\")\n",
    "print(f\"  Normal: {test_normal}\")\n",
    "print(f\"  Abnormal: {test_abnormal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b6c35f7-cd2a-4473-a936-39940fc24fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - accuracy: 0.7638 - loss: 0.4978 - val_accuracy: 0.8310 - val_loss: 0.3627\n",
      "Epoch 2/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 85ms/step - accuracy: 0.8241 - loss: 0.3677 - val_accuracy: 0.8521 - val_loss: 0.3358\n",
      "Epoch 3/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 85ms/step - accuracy: 0.8446 - loss: 0.3402 - val_accuracy: 0.8574 - val_loss: 0.3082\n",
      "Epoch 4/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 87ms/step - accuracy: 0.8711 - loss: 0.2991 - val_accuracy: 0.8869 - val_loss: 0.2661\n",
      "Epoch 5/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 93ms/step - accuracy: 0.8743 - loss: 0.2768 - val_accuracy: 0.8869 - val_loss: 0.2639\n",
      "Epoch 6/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.8939 - loss: 0.2564 - val_accuracy: 0.9023 - val_loss: 0.2307\n",
      "Epoch 7/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9054 - loss: 0.2259 - val_accuracy: 0.9102 - val_loss: 0.2274\n",
      "Epoch 8/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9053 - loss: 0.2227 - val_accuracy: 0.9120 - val_loss: 0.2117\n",
      "Epoch 9/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.9288 - loss: 0.1816 - val_accuracy: 0.9018 - val_loss: 0.2463\n",
      "Epoch 10/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - accuracy: 0.9247 - loss: 0.1847 - val_accuracy: 0.9305 - val_loss: 0.1962\n",
      "Epoch 11/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9312 - loss: 0.1707 - val_accuracy: 0.9247 - val_loss: 0.1924\n",
      "Epoch 12/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - accuracy: 0.9359 - loss: 0.1605 - val_accuracy: 0.9243 - val_loss: 0.1784\n",
      "Epoch 13/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9367 - loss: 0.1530 - val_accuracy: 0.9384 - val_loss: 0.1708\n",
      "Epoch 14/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 96ms/step - accuracy: 0.9486 - loss: 0.1305 - val_accuracy: 0.9318 - val_loss: 0.1818\n",
      "Epoch 15/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - accuracy: 0.9504 - loss: 0.1261 - val_accuracy: 0.9384 - val_loss: 0.1638\n",
      "Epoch 16/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - accuracy: 0.9432 - loss: 0.1247 - val_accuracy: 0.9247 - val_loss: 0.1964\n",
      "Epoch 17/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 97ms/step - accuracy: 0.9496 - loss: 0.1167 - val_accuracy: 0.9379 - val_loss: 0.1667\n",
      "Epoch 18/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - accuracy: 0.9539 - loss: 0.1113 - val_accuracy: 0.9357 - val_loss: 0.1708\n",
      "Epoch 19/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.9637 - loss: 0.0975 - val_accuracy: 0.9393 - val_loss: 0.1855\n",
      "Epoch 20/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 97ms/step - accuracy: 0.9589 - loss: 0.0950 - val_accuracy: 0.9454 - val_loss: 0.1902\n",
      "Epoch 21/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 114ms/step - accuracy: 0.9589 - loss: 0.1184 - val_accuracy: 0.9503 - val_loss: 0.1504\n",
      "Epoch 22/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 106ms/step - accuracy: 0.9706 - loss: 0.0746 - val_accuracy: 0.9489 - val_loss: 0.1724\n",
      "Epoch 23/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - accuracy: 0.9664 - loss: 0.0814 - val_accuracy: 0.9511 - val_loss: 0.1385\n",
      "Epoch 24/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 97ms/step - accuracy: 0.9746 - loss: 0.0692 - val_accuracy: 0.9551 - val_loss: 0.1477\n",
      "Epoch 25/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 96ms/step - accuracy: 0.9765 - loss: 0.0579 - val_accuracy: 0.9450 - val_loss: 0.1938\n",
      "Epoch 26/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - accuracy: 0.9714 - loss: 0.0728 - val_accuracy: 0.9569 - val_loss: 0.1376\n",
      "Epoch 27/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 95ms/step - accuracy: 0.9779 - loss: 0.0562 - val_accuracy: 0.9516 - val_loss: 0.1340\n",
      "Epoch 28/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 96ms/step - accuracy: 0.9723 - loss: 0.0697 - val_accuracy: 0.9599 - val_loss: 0.1375\n",
      "Epoch 29/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 93ms/step - accuracy: 0.9865 - loss: 0.0424 - val_accuracy: 0.9525 - val_loss: 0.1823\n",
      "Epoch 30/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 96ms/step - accuracy: 0.9841 - loss: 0.0441 - val_accuracy: 0.9560 - val_loss: 0.1680\n",
      "Epoch 31/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 96ms/step - accuracy: 0.9771 - loss: 0.0618 - val_accuracy: 0.9582 - val_loss: 0.1803\n",
      "Epoch 32/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 96ms/step - accuracy: 0.9753 - loss: 0.0807 - val_accuracy: 0.9560 - val_loss: 0.1688\n",
      "Epoch 33/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 104ms/step - accuracy: 0.9830 - loss: 0.0457 - val_accuracy: 0.9621 - val_loss: 0.1447\n",
      "Epoch 34/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 97ms/step - accuracy: 0.9794 - loss: 0.0615 - val_accuracy: 0.9591 - val_loss: 0.1592\n",
      "Epoch 35/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.9853 - loss: 0.0380 - val_accuracy: 0.9626 - val_loss: 0.1507\n",
      "Epoch 36/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - accuracy: 0.9875 - loss: 0.0391 - val_accuracy: 0.9635 - val_loss: 0.1532\n",
      "Epoch 37/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 96ms/step - accuracy: 0.9875 - loss: 0.0365 - val_accuracy: 0.9599 - val_loss: 0.1774\n",
      "Epoch 38/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - accuracy: 0.9924 - loss: 0.0249 - val_accuracy: 0.9582 - val_loss: 0.1734\n",
      "Epoch 39/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - accuracy: 0.9885 - loss: 0.0301 - val_accuracy: 0.9591 - val_loss: 0.1900\n",
      "Epoch 40/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - accuracy: 0.9790 - loss: 0.0509 - val_accuracy: 0.9516 - val_loss: 0.1805\n",
      "Epoch 41/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 95ms/step - accuracy: 0.9820 - loss: 0.0468 - val_accuracy: 0.9613 - val_loss: 0.1479\n",
      "Epoch 42/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 97ms/step - accuracy: 0.9865 - loss: 0.0359 - val_accuracy: 0.9665 - val_loss: 0.1436\n",
      "Epoch 43/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 94ms/step - accuracy: 0.9923 - loss: 0.0199 - val_accuracy: 0.9630 - val_loss: 0.1824\n",
      "Epoch 44/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - accuracy: 0.9908 - loss: 0.0287 - val_accuracy: 0.9621 - val_loss: 0.1969\n",
      "Epoch 45/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 97ms/step - accuracy: 0.9900 - loss: 0.0244 - val_accuracy: 0.9608 - val_loss: 0.1745\n",
      "Epoch 46/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - accuracy: 0.9905 - loss: 0.0271 - val_accuracy: 0.9652 - val_loss: 0.1896\n",
      "Epoch 47/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 95ms/step - accuracy: 0.9837 - loss: 0.0472 - val_accuracy: 0.9626 - val_loss: 0.1536\n",
      "Epoch 48/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 97ms/step - accuracy: 0.9901 - loss: 0.0272 - val_accuracy: 0.9595 - val_loss: 0.1990\n",
      "Epoch 49/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - accuracy: 0.9933 - loss: 0.0174 - val_accuracy: 0.9586 - val_loss: 0.1976\n",
      "Epoch 50/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.9958 - loss: 0.0133 - val_accuracy: 0.9586 - val_loss: 0.2014\n",
      "Epoch 51/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 94ms/step - accuracy: 0.9898 - loss: 0.0258 - val_accuracy: 0.9643 - val_loss: 0.1907\n",
      "Epoch 52/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.9849 - loss: 0.0442 - val_accuracy: 0.9674 - val_loss: 0.1573\n",
      "Epoch 53/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 94ms/step - accuracy: 0.9945 - loss: 0.0153 - val_accuracy: 0.9688 - val_loss: 0.1645\n",
      "Epoch 54/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9926 - loss: 0.0227 - val_accuracy: 0.9630 - val_loss: 0.1939\n",
      "Epoch 55/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - accuracy: 0.9916 - loss: 0.0235 - val_accuracy: 0.9564 - val_loss: 0.1737\n",
      "Epoch 56/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - accuracy: 0.9890 - loss: 0.0310 - val_accuracy: 0.9604 - val_loss: 0.1856\n",
      "Epoch 57/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 94ms/step - accuracy: 0.9893 - loss: 0.0375 - val_accuracy: 0.9696 - val_loss: 0.1758\n",
      "Epoch 58/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - accuracy: 0.9906 - loss: 0.0293 - val_accuracy: 0.9542 - val_loss: 0.1563\n",
      "Epoch 59/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 106ms/step - accuracy: 0.9925 - loss: 0.0235 - val_accuracy: 0.9692 - val_loss: 0.1824\n",
      "Epoch 60/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 101ms/step - accuracy: 0.9957 - loss: 0.0119 - val_accuracy: 0.9564 - val_loss: 0.2067\n",
      "Epoch 61/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 109ms/step - accuracy: 0.9906 - loss: 0.0279 - val_accuracy: 0.9679 - val_loss: 0.1498\n",
      "Epoch 62/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 108ms/step - accuracy: 0.9895 - loss: 0.0301 - val_accuracy: 0.9635 - val_loss: 0.1814\n",
      "Epoch 63/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 114ms/step - accuracy: 0.9937 - loss: 0.0169 - val_accuracy: 0.9639 - val_loss: 0.1713\n",
      "Epoch 64/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 105ms/step - accuracy: 0.9959 - loss: 0.0155 - val_accuracy: 0.9727 - val_loss: 0.1431\n",
      "Epoch 65/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - accuracy: 0.9955 - loss: 0.0097 - val_accuracy: 0.9705 - val_loss: 0.1687\n",
      "Epoch 66/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 107ms/step - accuracy: 0.9968 - loss: 0.0123 - val_accuracy: 0.9635 - val_loss: 0.2032\n",
      "Epoch 67/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 100ms/step - accuracy: 0.9913 - loss: 0.0264 - val_accuracy: 0.9648 - val_loss: 0.2182\n",
      "Epoch 68/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 98ms/step - accuracy: 0.9950 - loss: 0.0164 - val_accuracy: 0.9648 - val_loss: 0.1779\n",
      "Epoch 69/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - accuracy: 0.9896 - loss: 0.0275 - val_accuracy: 0.9705 - val_loss: 0.1821\n",
      "Epoch 70/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 98ms/step - accuracy: 0.9922 - loss: 0.0227 - val_accuracy: 0.9613 - val_loss: 0.1950\n",
      "Epoch 71/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 120ms/step - accuracy: 0.9962 - loss: 0.0113 - val_accuracy: 0.9670 - val_loss: 0.1997\n",
      "Epoch 72/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 128ms/step - accuracy: 0.9956 - loss: 0.0140 - val_accuracy: 0.9696 - val_loss: 0.2143\n",
      "Epoch 73/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 120ms/step - accuracy: 0.9941 - loss: 0.0192 - val_accuracy: 0.9393 - val_loss: 0.2345\n",
      "Epoch 74/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 110ms/step - accuracy: 0.9842 - loss: 0.0444 - val_accuracy: 0.9683 - val_loss: 0.1768\n",
      "Epoch 75/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 132ms/step - accuracy: 0.9937 - loss: 0.0223 - val_accuracy: 0.9696 - val_loss: 0.1712\n",
      "Epoch 76/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 108ms/step - accuracy: 0.9951 - loss: 0.0165 - val_accuracy: 0.9696 - val_loss: 0.1864\n",
      "Epoch 77/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 108ms/step - accuracy: 0.9968 - loss: 0.0096 - val_accuracy: 0.9683 - val_loss: 0.1970\n",
      "Epoch 78/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 110ms/step - accuracy: 0.9955 - loss: 0.0155 - val_accuracy: 0.9679 - val_loss: 0.2144\n",
      "Epoch 79/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 114ms/step - accuracy: 0.9921 - loss: 0.0198 - val_accuracy: 0.9621 - val_loss: 0.1942\n",
      "Epoch 80/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 110ms/step - accuracy: 0.9958 - loss: 0.0152 - val_accuracy: 0.9714 - val_loss: 0.1617\n",
      "Epoch 81/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 114ms/step - accuracy: 0.9967 - loss: 0.0085 - val_accuracy: 0.9732 - val_loss: 0.1957\n",
      "Epoch 82/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 118ms/step - accuracy: 0.9938 - loss: 0.0207 - val_accuracy: 0.9688 - val_loss: 0.1728\n",
      "Epoch 83/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 115ms/step - accuracy: 0.9950 - loss: 0.0158 - val_accuracy: 0.9657 - val_loss: 0.2385\n",
      "Epoch 84/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 116ms/step - accuracy: 0.9946 - loss: 0.0176 - val_accuracy: 0.9696 - val_loss: 0.1947\n",
      "Epoch 85/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 116ms/step - accuracy: 0.9943 - loss: 0.0207 - val_accuracy: 0.9727 - val_loss: 0.2097\n",
      "Epoch 86/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 117ms/step - accuracy: 0.9946 - loss: 0.0161 - val_accuracy: 0.9705 - val_loss: 0.2010\n",
      "Epoch 87/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 115ms/step - accuracy: 0.9976 - loss: 0.0078 - val_accuracy: 0.9732 - val_loss: 0.1906\n",
      "Epoch 88/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 115ms/step - accuracy: 0.9969 - loss: 0.0107 - val_accuracy: 0.9608 - val_loss: 0.2371\n",
      "Epoch 89/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 116ms/step - accuracy: 0.9926 - loss: 0.0211 - val_accuracy: 0.9670 - val_loss: 0.1855\n",
      "Epoch 90/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 122ms/step - accuracy: 0.9950 - loss: 0.0138 - val_accuracy: 0.9723 - val_loss: 0.2000\n",
      "Epoch 91/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 119ms/step - accuracy: 0.9961 - loss: 0.0211 - val_accuracy: 0.9736 - val_loss: 0.1864\n",
      "Epoch 92/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 122ms/step - accuracy: 0.9966 - loss: 0.0092 - val_accuracy: 0.9736 - val_loss: 0.1838\n",
      "Epoch 93/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 116ms/step - accuracy: 0.9943 - loss: 0.0179 - val_accuracy: 0.9688 - val_loss: 0.2050\n",
      "Epoch 94/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 119ms/step - accuracy: 0.9945 - loss: 0.0145 - val_accuracy: 0.9718 - val_loss: 0.1956\n",
      "Epoch 95/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 120ms/step - accuracy: 0.9966 - loss: 0.0101 - val_accuracy: 0.9665 - val_loss: 0.1929\n",
      "Epoch 96/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 126ms/step - accuracy: 0.9969 - loss: 0.0115 - val_accuracy: 0.9705 - val_loss: 0.2163\n",
      "Epoch 97/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 131ms/step - accuracy: 0.9945 - loss: 0.0172 - val_accuracy: 0.9569 - val_loss: 0.3040\n",
      "Epoch 98/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 125ms/step - accuracy: 0.9936 - loss: 0.0250 - val_accuracy: 0.9736 - val_loss: 0.1717\n",
      "Epoch 99/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 116ms/step - accuracy: 0.9952 - loss: 0.0225 - val_accuracy: 0.9692 - val_loss: 0.2208\n",
      "Epoch 100/100\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 115ms/step - accuracy: 0.9978 - loss: 0.0090 - val_accuracy: 0.9696 - val_loss: 0.2288\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9706 - loss: 0.2015\n",
      "Test Loss: 0.2288\n",
      "Test Accuracy: 0.9696\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 1. Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')  # 2 classes: Normal and Abnormal\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 3. Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_test, y_test))\n",
    "# Evaluate on test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3f8e09a-65db-4861-b4f4-a1d45e6f4e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Prediction probabilities: [[9.99878645e-01 1.21346995e-04]]\n",
      "Predicted class index: 0\n",
      "Prediction: Normal\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load and preprocess image\n",
    "img = load_img(r'C:\\Users\\Rashmi Bekal\\Project\\r1.jpeg', target_size=(64, 64), color_mode='rgb')\n",
    "img_array = img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Shape: (1, 64, 64, 3)\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(img_array)\n",
    "print(\"Prediction probabilities:\", prediction)\n",
    "\n",
    "class_index = np.argmax(prediction)\n",
    "print(\"Predicted class index:\", class_index)\n",
    "\n",
    "if class_index == 0:\n",
    "    print(\"Prediction: Normal\")\n",
    "else:\n",
    "    print(\"Prediction: Abnormal\")\n",
    "model.save('heart_attack_model.keras')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64039296-f538-4c42-a348-759175e5d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019a4ab2-6697-4d77-94ef-4be9b4d2bf5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f022e97-04f9-416f-a14d-909a9bb70752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rashmi Bekal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 10 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('heart_attack_model.keras')\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
